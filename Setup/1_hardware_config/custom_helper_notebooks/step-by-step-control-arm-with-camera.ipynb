{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d5473c9",
   "metadata": {},
   "source": [
    "# Functions to do\n",
    "- [ ] test camera\n",
    "- [ ] read servos\n",
    "- [ ] create widget group 1\n",
    "- [ ] create widget group 2\n",
    "- [ ] test the functionality of the buttons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c3ba59",
   "metadata": {},
   "source": [
    "# Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8999060",
   "metadata": {},
   "source": [
    "## Test the camera\n",
    "\n",
    "first we need to start the camera and see if it is reading something. Using similar code from the camera test and adjusting the shutdown code to the end of the code to see if we can run all parts simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f4b67b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:17:09.123993Z",
     "iopub.status.busy": "2025-04-16T22:17:09.122647Z",
     "iopub.status.idle": "2025-04-16T22:17:09.622380Z",
     "shell.execute_reply": "2025-04-16T22:17:09.619382Z",
     "shell.execute_reply.started": "2025-04-16T22:17:09.123863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the camera and widget libraries\n",
    "import cv2\n",
    "import ipywidgets.widgets as widgets\n",
    "import threading\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c9babb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:17:10.201257Z",
     "iopub.status.busy": "2025-04-16T22:17:10.200329Z",
     "iopub.status.idle": "2025-04-16T22:17:10.214928Z",
     "shell.execute_reply": "2025-04-16T22:17:10.209892Z",
     "shell.execute_reply.started": "2025-04-16T22:17:10.201164Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing helper function to create image format\n",
    "\n",
    "import enum\n",
    "import cv2\n",
    "\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec1f45e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:17:11.257250Z",
     "iopub.status.busy": "2025-04-16T22:17:11.256347Z",
     "iopub.status.idle": "2025-04-16T22:17:11.282700Z",
     "shell.execute_reply": "2025-04-16T22:17:11.279451Z",
     "shell.execute_reply.started": "2025-04-16T22:17:11.257164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b649b553734e7fb4d08652b464c23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='500', width='600')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the camera widget that will contain current camera \n",
    "image_widget = widgets.Image(format='jpeg', width=600, height=500)  \n",
    "display(image_widget)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb1a7ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:17:12.307428Z",
     "iopub.status.busy": "2025-04-16T22:17:12.305922Z",
     "iopub.status.idle": "2025-04-16T22:17:12.621107Z",
     "shell.execute_reply": "2025-04-16T22:17:12.618170Z",
     "shell.execute_reply.started": "2025-04-16T22:17:12.307268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here are the following options:\\n0. CV_CAP_PROP_POS_MSEC Current position of the video file in milliseconds.\\n1. CV_CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next.\\n2. CV_CAP_PROP_POS_AVI_RATIO Relative position of the video file\\n3. CV_CAP_PROP_FRAME_WIDTH Width of the frames in the video stream.\\n4. CV_CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream.\\n5. CV_CAP_PROP_FPS Frame rate.\\n6. CV_CAP_PROP_FOURCC 4-character code of codec.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open up the camera using cv2 with the width and \n",
    "\n",
    "\n",
    "# Create the videocapture using usb camera\n",
    "image = cv2.VideoCapture(0)  #Open camera\n",
    "\n",
    "''' Here are the following options:\n",
    "0. CV_CAP_PROP_POS_MSEC Current position of the video file in milliseconds.\n",
    "1. CV_CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next.\n",
    "2. CV_CAP_PROP_POS_AVI_RATIO Relative position of the video file\n",
    "3. CV_CAP_PROP_FRAME_WIDTH Width of the frames in the video stream.\n",
    "4. CV_CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream.\n",
    "5. CV_CAP_PROP_FPS Frame rate.\n",
    "6. CV_CAP_PROP_FOURCC 4-character code of codec.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11686b70",
   "metadata": {},
   "source": [
    "Extra options not used in code (commented out)\n",
    "<!-- \n",
    "7. CV_CAP_PROP_FRAME_COUNT Number of frames in the video file.\n",
    "8. CV_CAP_PROP_FORMAT Format of the Mat objects returned by retrieve() .\n",
    "9. CV_CAP_PROP_MODE Backend-specific value indicating the current capture mode.\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52755ea8",
   "metadata": {},
   "source": [
    "### Setting frame size and codec parameters for the video stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02d5708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:17:15.384710Z",
     "iopub.status.busy": "2025-04-16T22:17:15.383823Z",
     "iopub.status.idle": "2025-04-16T22:17:15.411086Z",
     "shell.execute_reply": "2025-04-16T22:17:15.406244Z",
     "shell.execute_reply.started": "2025-04-16T22:17:15.384623Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-5-6c083e240005>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-6c083e240005>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    ''''\u001b[0m\n\u001b[0m        \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "width=600\n",
    "height=500\n",
    "frame_rate=30\n",
    "\n",
    "# Example usage of constants and variables\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH,width)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT,height)\n",
    "\n",
    "# Example usage of number index if you don't want to use constant \n",
    "image.set(3,width)   # set width of the video frames\n",
    "image.set(4,height)  # set height of the video frames\n",
    "image.set(5, frame_rate)  # Set frame rate\n",
    "\n",
    "#  4-character code of codec used to compress the frames. \n",
    "'''\n",
    "For example:\n",
    "1. VideoWriter::fourcc('P','I','M','1') is a MPEG-1 codec \n",
    "2.VideoWriter::fourcc('M','J','P','G') is a motion-jpeg codec\n",
    "image.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))\n",
    "''''\n",
    "# also can use constant 6\n",
    "image.set(6, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0bce3",
   "metadata": {},
   "source": [
    "### Setting brightness/contrast/exposure of the camera stream\n",
    "\n",
    "- Settings configured\n",
    "    10. CV_CAP_PROP_BRIGHTNESS Brightness of the image (only for cameras).\n",
    "    11. CV_CAP_PROP_CONTRAST Contrast of the image (only for cameras).\n",
    "    12. CV_CAP_PROP_SATURATION Saturation of the image (only for cameras).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2e0cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:17:17.473951Z",
     "iopub.status.busy": "2025-04-16T22:17:17.471501Z",
     "iopub.status.idle": "2025-04-16T22:17:17.526480Z",
     "shell.execute_reply": "2025-04-16T22:17:17.518889Z",
     "shell.execute_reply.started": "2025-04-16T22:17:17.473719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.set(cv2.CAP_PROP_BRIGHTNESS, 40) #set brightness -64 - 64  0.0\n",
    "image.set(cv2.CAP_PROP_CONTRAST, 50)   #set contrast -64 - 64  2.0\n",
    "image.set(cv2.CAP_PROP_EXPOSURE, 156)  #set exposure 1.0 - 5000  156.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000cdfb",
   "metadata": {},
   "source": [
    "- Other image conversion options (not configured):\n",
    "\n",
    "    13. CV_CAP_PROP_HUE Hue of the image (only for cameras).\n",
    "    14. CV_CAP_PROP_GAIN Gain of the image (only for cameras).\n",
    "    15. CV_CAP_PROP_EXPOSURE Exposure (only for cameras).\n",
    "    16. CV_CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB.\n",
    "    17. CV_CAP_PROP_WHITE_BALANCE Currently unsupported\n",
    "    18. CV_CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d37bac9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:17:19.328433Z",
     "iopub.status.busy": "2025-04-16T22:17:19.327390Z",
     "iopub.status.idle": "2025-04-16T22:17:20.432802Z",
     "shell.execute_reply": "2025-04-16T22:17:20.427461Z",
     "shell.execute_reply.started": "2025-04-16T22:17:19.328336Z"
    }
   },
   "outputs": [],
   "source": [
    "# read the camera data and return a boolean if it read correctly and the frame itself\n",
    "ret, frame = image.read()     #Read camera data\n",
    "\n",
    "# add the adjusted frame to the image_widget with jpeg format (for easy accessibility)\n",
    "image_widget.value = bgr8_to_jpeg(frame) # convert the frame to jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83716578",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Servo\n",
    "\n",
    "### Program functions:\n",
    "\n",
    "Servos:\n",
    "1. No. 1 Servo: \n",
    "    - Directions:  The left and right directions control the left and right movement of the No. 1 servo\n",
    "    - Max-Min Range: \n",
    "    - Adjusted Range of Safe Movement\n",
    "\n",
    "\n",
    "2. No. 2 Servo\n",
    "    - Directions:  The up and down directions control the forward and backward movement of the No. 2 servo.\n",
    "\n",
    "3. No. 3 Servo\n",
    "    - Directions: The No. 3 servo control to move forward or backward.\n",
    "    - \n",
    "\n",
    "4. No. 4 Servo\n",
    "    - Directions: the No. 4 servo to move forward or backward.\n",
    "\n",
    "> Note: we will not use the No. 5 and No. 6 Servo for the sake of the experiment (commented below for reference)\n",
    "<!-- 2. The right joystick and number keys control the No. 5 and No. 6 servos. The left and right directions control the left and right rotation of the No. 5 servo, and the up and down directions control the clamping and loosening of the No. 6 servo.\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e2c5f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Testing No. 1 Servo (left and Right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604feb80",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Widget Group 1: Create python widget with 2 button for each servo step \n",
    "This will be used to see how the servos work in conjunction to movement which will help create low-level code to configure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b988b1c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Widget Group 2: Create python widget with only 4 main directional buttons to mimic the common movement of human neck (up, down, left, right) without individual servo buttons \n",
    "This will be used to narrow down the basic movements that don't factor in the individual servos (but still will output logs) as humans don't take into considerations of the individual muscles when looking at an opject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e265050f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Test Full functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02318c57",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Shut down camera, arm, and widgets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
