{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6adc8f5f",
   "metadata": {},
   "source": [
    "**Table of contents**    \n",
    "- 2-d object detection    \n",
    "  - Methodology Explanation    \n",
    "  - Running Code Visualization (2-d object detection)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=false\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd8dcf",
   "metadata": {},
   "source": [
    "# 2-d object detection\n",
    "Here is the code that runs the 2-d object detection model. It uses the `detectron2` library to perform object detection on images. The code loads a pre-trained model, processes the input image, and visualizes the detected objects with bounding boxes and labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c49e2",
   "metadata": {},
   "source": [
    "## Methodology Explanation\n",
    "\n",
    "The color detection is a great first step to tackling the bigger because it allows us to filter out the background and focus on the objects of interest. However, it is not sufficient for detecting complex objects that may have multiple colors or patterns. So let's take the chance to explore and implement a more advanced method for detecting objects in images.\n",
    "\n",
    "\n",
    "\n",
    "I came across a few different libraries that can be used for object detection, including, `tensorflow`, `detectron2`, `YOLO`, and `OpenCV`.\n",
    "\n",
    "In order to navigate through the many options available, I decided to go with `detectron2` as it is a popular library for object detection and segmentation tasks. It is built on top of `PyTorch` and provides a high-level API for building and training object detection models.\n",
    " Fortunately, this ended up being a great decision as I stumbled across a brilliant implentation of `OpenCV` for object detection in which the designer had utilized the dataset from the `COCO` dataset. This is a large-scale object detection, segmentation, and captioning dataset that contains over 330k images and 80 object categories. The dataset is widely used in the computer vision community and has become a standard benchmark for object detection algorithms.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " we will use the `detectron2` library, which is a popular library for object detection and segmentation tasks. The code will perform the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "image"
    ]
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import Arm_Lib\n",
    "import cv2 as cv\n",
    "import threading\n",
    "from time import sleep\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from single_garbage_identify import single_garbage_identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_garbage = single_garbage_identify()\n",
    "model = \"General\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_layout      = widgets.Layout(width='320px', height='60px', align_self='center')\n",
    "output = widgets.Output()\n",
    "# Exit\n",
    "exit_button = widgets.Button(description='Exit', button_style='danger', layout=button_layout)\n",
    "imgbox = widgets.Image(format='jpg', height=480, width=640, layout=widgets.Layout(align_self='center'))\n",
    "controls_box = widgets.VBox([imgbox, exit_button], layout=widgets.Layout(align_self='center'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_button_Callback(value):\n",
    "    global model\n",
    "    model = 'Exit'\n",
    "    with output: print(model)\n",
    "exit_button.on_click(exit_button_Callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera():\n",
    "    # Open camera\n",
    "    capture = cv.VideoCapture(0)\n",
    "    # Loop execution when the camera is opened normally\n",
    "    while capture.isOpened():\n",
    "        try:\n",
    "            _, img = capture.read()\n",
    "            img = cv.resize(img, (640, 480))\n",
    "            img = single_garbage.single_garbage_run(img)\n",
    "            if model == 'Exit':\n",
    "                cv.destroyAllWindows()\n",
    "                capture.release()\n",
    "                break\n",
    "            imgbox.value = cv.imencode('.jpg', img)[1].tobytes()\n",
    "        except KeyboardInterrupt:capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please place the building block in the center of the cross (the picture is facing the mechanical arm)\n",
    "# Please place the building block in the center of the cross (the picture is facing the mechanical arm)\n",
    "display(controls_box, output)\n",
    "threading.Thread(target=camera, ).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:\n",
    "\n",
    "# 1. The first time you run the code, the model will be downloaded and saved in the current directory\n",
    "# 2. The second time you run the code, the model will be loaded from the current directory\n",
    "# 3. The model will be automatically updated every 30 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a44f5",
   "metadata": {},
   "source": [
    "## Running Code Visualization (2-d object detection)\n",
    "\n",
    "- loading the pre-trained model\n",
    "\n",
    "![Running advanced feature code implementation](../../../etc/imgs/running_advanced_feature_code_implementation.gif)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3891e24",
   "metadata": {},
   "source": [
    "\n",
    "- visualizing the detected objects with bounding boxes and labels\n",
    "\n",
    "![identify_no_object_identified.png](../../../etc/imgs/identify-2-d-object.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d43e5",
   "metadata": {},
   "source": [
    "- No detection with multiple items\n",
    "\n",
    " ![No detection with multiple objects](../../../etc/imgs/identify_no_detection_with_multiple_objects.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
